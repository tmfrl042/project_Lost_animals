{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 import 위에서부터 하나하나 실행하면 문제없이 작동하는 것 같습니다.\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "#from flask import Flask, render_template, jsonify, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 브라우져 오픈\n",
    "chromedriver=\"C:/LSW/PYDATAexam/Webdriver/chromedriver\"\n",
    "driver=webdriver.Chrome(chromedriver)\n",
    "headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링할 데이터를 저장할 리스트를 미리 만들어 두었습니다.\n",
    "url_list = []\n",
    "title_list = []\n",
    "writer_list = []\n",
    "blogname_list=[]\n",
    "content_list = []\n",
    "date_list=[]\n",
    "img_url_list=[]\n",
    "index_list=list(range(0,len(title_list)))\n",
    "\n",
    "# 원하는 검색어를 이용하면 원하는 내용의 블로그 검색이 가능합니다.\n",
    "text = \"유기견 보호소\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url 수집 끝, 해당 url 데이터 크롤링\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):  # 1~(n-1)페이지까지의 블로그 내용을 읽어옴\n",
    "    url = 'https://section.blog.naver.com/Search/Post.nhn?pageNo='+ str(i) + '&rangeType=ALL&orderBy=sim&keyword=' + text\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    # 한 페이지당 7개의 블로그 창이 뜨기때문에 페이지마다 7개의 데이터를 크롤링 해옵니다.\n",
    "    for j in range(0, 7): \n",
    "        # 블로그에 적은 글의 주소가 저장된 위치를 찾고 리스트에 저장합니다.\n",
    "        links=driver.find_elements_by_css_selector(\"#content > section > div.area_list_search > div > div > div.info_post > div.desc > a.desc_inner\")\n",
    "        link = links[j].get_attribute('href')\n",
    "        url_list.append(link)\n",
    "\n",
    "        # 블로그에 글쓴 사람의 닉네임의 위치를 찾고 리스트에 저장합니다.\n",
    "        writers=driver.find_elements_by_css_selector(\"#content > section > div.area_list_search > div > div > div.info_post > div.writer_info\")\n",
    "        writer=writers[j].find_element_by_css_selector('em').text\n",
    "        writer_list.append(writer)\n",
    "        \n",
    "        # 블로그의 이름을 뽑아내고, 리스트에 저장합니다.\n",
    "        blog_name=writers[j].find_element_by_css_selector('span').text\n",
    "        blogname_list.append(blog_name)\n",
    "        \n",
    "        # 글쓴 날짜를 뽑아내고, 리스트에 저장합니다.\n",
    "        write_date=writers[j].find_element_by_css_selector('.date').text\n",
    "        date_list.append(write_date)\n",
    "\n",
    "        # 블로그에 글의 제목의 위치를 찾습니다. 리스트에 저장합니다.\n",
    "        titles=driver.find_elements_by_css_selector(\"#content > section > div.area_list_search > div > div > div.info_post > div.desc > a.desc_inner > strong > span\")\n",
    "        title=titles[j].text\n",
    "        title_list.append(title)\n",
    "        \n",
    "        # 블로그의 이미지 url의 위치를 찾고 저장합니다.\n",
    "        #img_links=driver.find_elements_by_css_selector(\"#content > section > div.area_list_search > div > div > div.thumbnail_post > div > a.thumbnail_inner > img\")\n",
    "        #img_link=img_links[j].get_attribute('src')\n",
    "        #img_url_list.append(img_link)\n",
    "        \n",
    "\n",
    "# 상황에 따라 길어질 수 있으므로 수집이 끝나면 알 수 있도록 이를 출력해 줍니다.\n",
    "print(\"url 수집 끝, 해당 url 데이터 크롤링\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "# 네이버 블로그를 통한 사진 url 저장을 해보니 불가능해서 다른 곳에서 크롤링을 시도해보았습니다.(구글링 코드 수정함)\n",
    "# 필요한 패키지 import 위에서부터 하나하나 실행하면 문제없이 작동하는 것 같습니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "chromedriver=\"C:/LSW/PYDATAexam/Webdriver/chromedriver\"\n",
    "driver=webdriver.Chrome(chromedriver)\n",
    "text2=\"유기견 강아지\"\n",
    "driver.get(\"https://search.naver.com/search.naver?sm=tab_hty.top&where=image&query=\"+text2) # 여기에 URL을 넣어주세요\n",
    "time.sleep(3)\n",
    "\n",
    "req = driver.page_source\n",
    "soup = BeautifulSoup(req, 'html.parser')\n",
    "thumbnails = soup.select('div > div.thumb > a > img')\n",
    "\n",
    "for thumbnail in thumbnails[0:len(title_list)]:\n",
    "    img = thumbnail['src']\n",
    "    img_url_list.append(img)\n",
    "print(len(img_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "본문 내용 수집이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 수집한 url마다 들어갑니다.\n",
    "for url in url_list: # 수집한 url 만큼 반복\n",
    "    driver.get(url) # 해당 url로 이동\n",
    "    driver.switch_to.frame('mainFrame') # 찾아봐도 이해가 안되는 내용, 그냥 크롤링이 불가능 하므로 id가 mainframe인 창으로 이동하고\n",
    "    # 본문의 내용을 찾아서\n",
    "    overlays = \".se-main-container\"  \n",
    "    contents = driver.find_elements_by_css_selector(overlays)\n",
    "    # 리스트에 저장합니다.\n",
    "    content_list.append(contents[0].text.replace(\"\\n\",\" \"))\n",
    "\n",
    "# 상황에 따라 길어질 수 있으므로 수집이 끝나면 알 수 있도록 이를 출력해 줍니다.\n",
    "print(\"본문 내용 수집이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONGO DB에 저장합니다.\n",
    "client = MongoClient('localhost', 27017)\n",
    "# 이름이 db_animal인 DB를 이용합니다 없다면 만듭니다.\n",
    "db = client.db_animal\n",
    "for i in list(range(0,len(title_list))):\n",
    "    doc={'title': title_list[i],'url':url_list[i],'writer': writer_list[i], 'content': content_list[i],'date':date_list[i],'img_url':img_url_list[i]}\n",
    "    db.blogs.insert_one(doc)# blogs라는 collections에 데이터들을 저장합니다. 끝!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
